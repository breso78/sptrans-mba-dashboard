{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f0044b1-2e73-43a2-a3cb-48d510c8f636",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ingestão diária (ou caso haja alteração em documentação)"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.sptrans.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Não encontrado no ZIP: /tmp/temp_gtfs/calendar_dates.txt\n✅ GTFS atualizado carregado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "GTFS_URL = \"https://www.sptrans.com.br/umbraco/Surface/PerfilDesenvolvedor/BaixarGTFS?memberName=sptrans\"\n",
    "GTFS_PATH = \"/Volumes/workspace/sptrans/bronze/gtfs\"\n",
    "TEMP_LOCAL = \"/tmp/temp_gtfs\"\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import current_date\n",
    "import os\n",
    "\n",
    "# Download e extração\n",
    "r = requests.get(GTFS_URL, verify=False)  # alguns servidores exigem verify=False\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall(TEMP_LOCAL)\n",
    "\n",
    "files = [\n",
    "    \"agency.txt\", \"routes.txt\", \"trips.txt\", \"stops.txt\",\n",
    "    \"stop_times.txt\", \"shapes.txt\", \"calendar.txt\", \"calendar_dates.txt\",\n",
    "    \"frequencies.txt\", \"fare_attributes.txt\", \"fare_rules.txt\"\n",
    "]\n",
    "\n",
    "for f in files:\n",
    "    local_path = f\"{TEMP_LOCAL}/{f}\"\n",
    "    if os.path.exists(local_path):\n",
    "        pdf = pd.read_csv(local_path)\n",
    "        df = spark.createDataFrame(pdf).withColumn(\"load_date\", current_date())\n",
    "\n",
    "        df.write.format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .saveAsTable(f\"workspace.sptrans.bronze_gtfs_{f.replace('.txt','')}\")\n",
    "    else:\n",
    "        print(f\"⚠ Não encontrado no ZIP: {local_path}\")\n",
    "\n",
    "print(\"✅ GTFS atualizado carregado com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ingestao_gtfs_diario",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}